{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JN1yC21-4NZn"
   },
   "source": [
    "# 1. Preperation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEF1DFXb4OnQ"
   },
   "source": [
    "###(a) import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u7JQSDzDrj6w"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys, requests, shutil, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjC_mGnf46sO"
   },
   "source": [
    "### (b) Mount notebook to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "gGuflOvcsRWI",
    "outputId": "ebc7ed10-8d01-4cd1-a309-13c5f36aa739"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9e270757613c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Mount my Google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;34m': timeout during initial read of root folder; for more info: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             'https://research.google.com/colaboratory/faq.html#drive-timeout')\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;31m# Not already authorized, so do the authorization dance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed: timeout during initial read of root folder; for more info: https://research.google.com/colaboratory/faq.html#drive-timeout"
     ]
    }
   ],
   "source": [
    "#Mount my Google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAs-mTZD5Fuv"
   },
   "source": [
    "###(c) Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbLTHfCc4pLy"
   },
   "outputs": [],
   "source": [
    "path = \"/content/drive/My Drive/APM_B10/train.csv\" #directory for data\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "4szxGOEpr4gg",
    "outputId": "13718233-c6d6-432a-8457-609a84063345"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97c0a12e07ae8dd5</td>\n",
       "      <td>http://lh4.ggpht.com/-f8xYA5l4apw/RSziSQVaABI/...</td>\n",
       "      <td>6347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650c989dd3493748</td>\n",
       "      <td>https://lh5.googleusercontent.com/-PUnMrX7oOyA...</td>\n",
       "      <td>12519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05e63ca9b2cde1f4</td>\n",
       "      <td>http://mw2.google.com/mw-panoramio/photos/medi...</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08672eddcb2b7c93</td>\n",
       "      <td>http://lh3.ggpht.com/-9fgSxDYwhHA/SMvGEoltKTI/...</td>\n",
       "      <td>13287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fc49cb32ef7f1e89</td>\n",
       "      <td>http://lh6.ggpht.com/-UGAXxvPbr98/S-jGZbyMIPI/...</td>\n",
       "      <td>4018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  ... landmark_id\n",
       "0  97c0a12e07ae8dd5  ...        6347\n",
       "1  650c989dd3493748  ...       12519\n",
       "2  05e63ca9b2cde1f4  ...         264\n",
       "3  08672eddcb2b7c93  ...       13287\n",
       "4  fc49cb32ef7f1e89  ...        4018\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RbNfRaks32v",
    "outputId": "1102c8b6-4c05-4a07-b165-1ff269bd0d27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1225029, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pSmF5QrvT1h"
   },
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n90O8ayH6YRx"
   },
   "source": [
    "#2. EDA:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T41FuMt66_Is"
   },
   "source": [
    "###(a) Sampling and data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4K0dCns6amA"
   },
   "outputs": [],
   "source": [
    "#Sample only landmark_id from 1000-2000 to save time\n",
    "landmark_list = [str(x) for x in list(range(1000,2000))]\n",
    "data_sample = df[df['landmark_id'].isin(landmark_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LrdJPEM6a0p"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import subplots\n",
    "\n",
    "colors = np.array(['#4285f4','#34a853','#fbbc05','#ea4335'])\n",
    "#Define the order in which to display the graph\n",
    "order = ['1-5','5-10','10-50','50-100','100-200','200-500','>=500']\n",
    "f, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n",
    "\n",
    "\n",
    "def plot_distribution(data_f, data_k, axis):\n",
    "    # data['landmark_id'].value_counts()\n",
    "    x=data_f.landmark_id.value_counts().index\n",
    "    y=pd.DataFrame(data_f.landmark_id.value_counts())\n",
    "\n",
    "    #Create a variable to group the number of image sin each class\n",
    "    y['Number of images'] = np.where(y['landmark_id']>=500,'>=500',y['landmark_id'])\n",
    "    y['Number of images'] = np.where((y['landmark_id']>=200) & (y['landmark_id']<500),'200-500',y['Number of images'])\n",
    "    y['Number of images'] = np.where((y['landmark_id']>=100) & (y['landmark_id']<200),'100-200',y['Number of images'])\n",
    "    y['Number of images'] = np.where((y['landmark_id']>=50) & (y['landmark_id']<100),'50-100',y['Number of images'])\n",
    "    y['Number of images'] = np.where((y['landmark_id']>=10) & (y['landmark_id']<50),'10-50',y['Number of images'])\n",
    "    y['Number of images'] = np.where((y['landmark_id']>=5) & (y['landmark_id']<10),'5-10',y['Number of images'])\n",
    "    y['Number of images'] = np.where((y['landmark_id']>=0) & (y['landmark_id']<5),'1-5',y['Number of images'])\n",
    "\n",
    "    y['Number of images'].value_counts().loc[order].plot(kind = 'bar',color = colors,width = 0.8, ax=axis)\n",
    "    axis.set_xlabel('Number of images')\n",
    "    axis.set_ylabel('Number of classes')\n",
    "    axis.set_title(data_k)\n",
    "    \n",
    "plot_distribution(data, 'Original', ax1)\n",
    "plot_distribution(data_sample, 'Sample', ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0O4wSjT7e07"
   },
   "source": [
    "Sample shows similar distribution as fullset of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzynRvYo7Ku7"
   },
   "source": [
    "###(b) Display one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEI54G2_vggB"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "def display_image(url):\n",
    "    img_style = \"width: 500px; margin: 0px; float: left; border: 1px solid black;\"\n",
    "    image=f\"<img style='{img_style}' src='{url}' />\"\n",
    "    display(HTML(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgYvDoT2w7TF",
    "outputId": "30350e84-3ae2-4571-a539-e3e037d41c06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style='width: 500px; margin: 0px; float: left; border: 1px solid black;' src='https://lh4.googleusercontent.com/-zL3zuE1cMH8/TSewvqdGx7I/AAAAAAAAAOo/x4PeUg8Ln8c/s1600/' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(df['url'][155])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ey0GKEa74gN"
   },
   "source": [
    "###(c) Further exploring and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RrWjWBeuxB4w",
    "outputId": "c8463d44-603a-4772-ef08-84e2ab91c0b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9633    49465\n",
       "6051    49238\n",
       "None    33763\n",
       "6599    22774\n",
       "9779    18069\n",
       "        ...  \n",
       "9246        1\n",
       "904         1\n",
       "6942        1\n",
       "5745        1\n",
       "8859        1\n",
       "Name: landmark_id, Length: 14947, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many images does each landmark has?\n",
    "df['landmark_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68AADcUFxGtN",
    "outputId": "08af54fc-2c0f-4083-97be-ccf3111c5ed4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "url            0\n",
       "landmark_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many null value are there?\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5grcI6pC3nqj",
    "outputId": "d16cff17-fb77-402c-85d6-67b2e62d1613"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14947"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many unqiue landmark class are there?\n",
    "len(df['landmark_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnWkkBsi3p-E",
    "outputId": "6a2bc236-1ca0-49d9-a3b8-86dd49fc6b66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes under 20 occurences 8880 out of total number of categories 14947\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of classes under 100 occurences\",(df['landmark_id'].value_counts() <= 100).sum(),\n",
    "      'out of total number of categories',len(df['landmark_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MzsYT4866hH"
   },
   "outputs": [],
   "source": [
    "#keeping only classes with 100 or more images, to gurantee 1% test split later.\n",
    "filtered = df.groupby('landmark_id')['url'].filter(lambda x: len(x) >= 100)\n",
    "df_filter = df[df['url'].isin(filtered)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "sxBAFdh28nz3",
    "outputId": "17e01df5-e4f6-41ca-a3f2-caac2ee224b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97c0a12e07ae8dd5</td>\n",
       "      <td>http://lh4.ggpht.com/-f8xYA5l4apw/RSziSQVaABI/...</td>\n",
       "      <td>6347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650c989dd3493748</td>\n",
       "      <td>https://lh5.googleusercontent.com/-PUnMrX7oOyA...</td>\n",
       "      <td>12519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05e63ca9b2cde1f4</td>\n",
       "      <td>http://mw2.google.com/mw-panoramio/photos/medi...</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>056708de792326b9</td>\n",
       "      <td>https://lh3.googleusercontent.com/-nbz_XT1dGz4...</td>\n",
       "      <td>5046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6ae1e206c579f649</td>\n",
       "      <td>https://lh6.googleusercontent.com/-onL5-pK9nZI...</td>\n",
       "      <td>5554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225024</th>\n",
       "      <td>4bb5a501e5b26a6a</td>\n",
       "      <td>https://lh6.googleusercontent.com/-mRrQU3t5cYw...</td>\n",
       "      <td>9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225025</th>\n",
       "      <td>2cd8a404796cfe0e</td>\n",
       "      <td>https://lh6.googleusercontent.com/-0UB5gFx6w7M...</td>\n",
       "      <td>7758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225026</th>\n",
       "      <td>8733b8b469fb8c1b</td>\n",
       "      <td>http://lh3.ggpht.com/-TDQWNVvJQDI/SI3HZSA4D3I/...</td>\n",
       "      <td>13170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225027</th>\n",
       "      <td>14dd9e8790397c83</td>\n",
       "      <td>https://lh4.googleusercontent.com/-anV4Xpo0UuM...</td>\n",
       "      <td>5669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225028</th>\n",
       "      <td>4303049d5a6b5602</td>\n",
       "      <td>https://lh6.googleusercontent.com/-1pe3ldzCDAw...</td>\n",
       "      <td>4987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>935832 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  ... landmark_id\n",
       "0        97c0a12e07ae8dd5  ...        6347\n",
       "1        650c989dd3493748  ...       12519\n",
       "2        05e63ca9b2cde1f4  ...         264\n",
       "5        056708de792326b9  ...        5046\n",
       "6        6ae1e206c579f649  ...        5554\n",
       "...                   ...  ...         ...\n",
       "1225024  4bb5a501e5b26a6a  ...        9737\n",
       "1225025  2cd8a404796cfe0e  ...        7758\n",
       "1225026  8733b8b469fb8c1b  ...       13170\n",
       "1225027  14dd9e8790397c83  ...        5669\n",
       "1225028  4303049d5a6b5602  ...        4987\n",
       "\n",
       "[935832 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter = df_filter.replace(to_replace='None', value=np.nan).dropna()\n",
    "df_filter\n",
    "#df_filter contains data without \"None\" as landmark_id AND only landmark_id with more than 100 urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbHIebL49KbM"
   },
   "source": [
    "###(d) Preview mutiple images belong to same class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cATub4G7-pT-"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "def display_category(urls):\n",
    "    img_style = \"width: 180px; margin: 0px; float: left; border: 1px solid black;\"\n",
    "    images_list = ''.join([f\"<img style='{img_style}' src='{u}' />\" for _, u in urls.head(12).iteritems()])\n",
    "    display(HTML(images_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "id": "dZPd-HCZ-1Rc",
    "outputId": "fe654b09-e96e-407a-9910-880bb97bbf77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='https://lh5.googleusercontent.com/-7AoJnw2esWw/S7ubehzXuuI/AAAAAAAAAXw/NKnaXkpx1wU/s1600/' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='https://lh6.googleusercontent.com/-xAmqD_PLM28/RrAE2_jmP0I/AAAAAAAACCU/Vq7NPptikCU/s1600/' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='https://lh6.googleusercontent.com/-QCDV0ENYxPI/SKfNbKY2CtI/AAAAAAAABxA/UIj8746bUTw/s0-d/' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='https://lh3.googleusercontent.com/-oYFvHLf8HEQ/TWgcpFrOyiI/AAAAAAAAD0k/o5S4beoVNn0/rj/' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='https://lh5.googleusercontent.com/-Q15GMLfJpdc/TlJ6IQYpJaI/AAAAAAAAGxM/jYbRZpAFaKA/s1600/' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='http://lh3.ggpht.com/-zKaU4XvjeFE/R5XRfHXJxRI/AAAAAAAAECQ/fPg2QeEKgJA/s1600/' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='https://lh4.googleusercontent.com/-xDQcOL79zRA/RfOxtZ7rMvI/AAAAAAAAAIk/AW7_H1k4AJ4/s1600/' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='http://mw2.google.com/mw-panoramio/photos/medium/81377771.jpg' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='https://lh6.googleusercontent.com/-ZqiOKkKOllk/Sc0_VSbDaEI/AAAAAAAAAR8/kk15skmgHUw/s1600/' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='https://lh6.googleusercontent.com/-6yVrVaWwh14/TGhNUwwuPYI/AAAAAAAAEIw/RbT98dNc-5E/s1600/' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='http://lh3.ggpht.com/-PM2nPSJAYXQ/ThyU4qqAPtI/AAAAAAAAA50/wlLR37Q-4WY/s1600/' /><img style='width: 180px; margin: 0px; float: left; border: 1px solid black;' src='http://lh4.ggpht.com/-LSvdTRgXZ2Y/T946lDHZuZI/AAAAAAAAMOU/8VCh1WgnnI8/s1600/' />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "category = df_filter['landmark_id'].value_counts().keys()[0]\n",
    "urls = df_filter[df_filter['landmark_id'] == category]['url']\n",
    "display_category(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoKOH4_W-ABg"
   },
   "source": [
    "### (e) Final data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mxo4_PFBDgo"
   },
   "outputs": [],
   "source": [
    "#Select only id from 1000-2000 to save time\n",
    "landmark_list = [str(x) for x in list(range(1000,2000))] #changed from 1000-3000 to 2000\n",
    "data_sample = df_filter[df_filter['landmark_id'].isin(landmark_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "DJqsJBx9lrCv",
    "outputId": "8422e5ef-9fbd-4fa1-f017-91e7cd8e7ea5"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_cbf083aa-22cf-411e-bdb2-4bfc97dcc55b\", \"clean_data.csv\", 5627833)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Save final sample as csv file to avoid re-running the above code everytime.\n",
    "data_sample.to_csv('clean_data.csv', index=False)\n",
    "files.download('clean_data.csv')\n",
    "#Need to write read.csv function if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bI6JYUAy-c6S"
   },
   "source": [
    "#3. Downloading Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnVjvyUA-fy9"
   },
   "source": [
    "###(a) Change URLs to resize images to target size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XK-aIF2HfzjI",
    "outputId": "67e0452e-a0a2-4c95-acdf-9b1a561ebb46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. URLs overwritten\n"
     ]
    }
   ],
   "source": [
    "#Ref: https://www.kaggle.com/lyakaap/fast-resized-image-download-python-3\n",
    "import re\n",
    "TARGET_SIZE = 96 #imports images of resolution 96x96\n",
    "\n",
    "def overwrite_urls(df):\n",
    "    def reso_overwrite(url_tail, reso=TARGET_SIZE):\n",
    "        pattern = 's[0-9]+'\n",
    "        search_result = re.match(pattern, url_tail)\n",
    "        if search_result is None:\n",
    "            return url_tail\n",
    "        else:\n",
    "            return 's{}'.format(reso)\n",
    "    \n",
    "    def join_url(parsed_url, s_reso):\n",
    "        parsed_url[-2] = s_reso\n",
    "        return '/'.join(parsed_url)\n",
    "    \n",
    "    df = df[df.url.apply(lambda x: len(x.split('/'))>1)]\n",
    "    parsed_url = df.url.apply(lambda x: x.split('/'))\n",
    "    train_url_tail = parsed_url.apply(lambda x: x[-2])\n",
    "    resos = train_url_tail.apply(lambda x: reso_overwrite(x, reso=TARGET_SIZE))\n",
    "\n",
    "    overwritten_df = pd.concat([parsed_url, resos], axis=1)\n",
    "    overwritten_df.columns = ['url', 's_reso']\n",
    "    df['url'] = overwritten_df.apply(lambda x: join_url(x['url'], x['s_reso']), axis=1)\n",
    "    return df\n",
    "\n",
    "data_sample_resize = overwrite_urls(data_sample)\n",
    "print ('1. URLs overwritten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laN3ryatpJvB"
   },
   "outputs": [],
   "source": [
    "#Identify images URL with panoramio that's no longer supported by Google\n",
    "bad_word='panoramio'\n",
    "panoramio_list=[]\n",
    "data_sample_resize['url']\n",
    "for i in data_sample_resize['url']:\n",
    "  if bad_word in i:\n",
    "    panoramio_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dHgssVSf2l5",
    "outputId": "94c04a7f-5b4a-42c1-baac-da521eb0a35f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    45860\n",
       "True      7494\n",
       "Name: url, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new=pd.DataFrame(columns = ['id','url','landmark_id'])\n",
    "new['url']=data_sample_resize['url'] == data_sample['url']\n",
    "new['url'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg9xtMNAcbmu"
   },
   "source": [
    "###(b) Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIjRthXdBBMn"
   },
   "outputs": [],
   "source": [
    "data_test = pd.DataFrame(columns = ['id','url','landmark_id'])\n",
    "data_training_all = pd.DataFrame(columns = ['id','url','landmark_id'])\n",
    "percent_test = 0.01 #takes 1% from each class as holdout data\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "for landmark_id in set(data_sample_resize['landmark_id']):\n",
    "    n=1\n",
    "    t = data_sample_resize[(data_sample_resize.landmark_id == landmark_id)] #get all images for a landmark id\n",
    "    i = 0\n",
    "    r =[]\n",
    "    while i < len(t.id):\n",
    "        it = i\n",
    "        r.append(t.id.iloc[it])  #create a list of all these images\n",
    "        i += 1\n",
    "        \n",
    "    test = random.sample(r,int(percent_test*len(r))) #randomly pick a sample of 1% images from list 'r'\n",
    "    training = list(set(r) - set(test))  #get the remaining images\n",
    "    data_t = data_sample_resize[data_sample_resize.id.isin(test)] #holdout dataset\n",
    "    data_tr = data_sample_resize[data_sample_resize.id.isin(training)] #training dataset\n",
    "    data_test = data_test.append(data_t)  \n",
    "    data_training_all = data_training_all.append(data_tr)\n",
    "    n+=1\n",
    "\n",
    "print ('2. train and test set created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIXwoFyEBNty"
   },
   "source": [
    "###(c)Train_Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_89WJ0BBW6v"
   },
   "outputs": [],
   "source": [
    "data_valid = pd.DataFrame(columns = ['id','url','landmark_id'])\n",
    "data_train = pd.DataFrame(columns = ['id','url','landmark_id'])\n",
    "percent_validation = 0.2 #takes 20% from each class as holdout data\n",
    "import random\n",
    "random.seed(42)\n",
    "for landmark_id in set(data_training_all['landmark_id']):\n",
    "    n=1\n",
    "    t = data_training_all[(data_training_all.landmark_id == landmark_id)]\n",
    "    i = 0\n",
    "    r =[]\n",
    "    while i < len(t.id):\n",
    "        it = i\n",
    "        r.append(t.id.iloc[it])\n",
    "        i += 1\n",
    "        \n",
    "    valid = random.sample(r,int(percent_validation*len(r)))\n",
    "    train = list(set(r) - set(valid)) \n",
    "    data_v = data_training_all[data_training_all.id.isin(valid)]\n",
    "    data_t = data_training_all[data_training_all.id.isin(train)]\n",
    "    data_valid = data_valid.append(data_v)\n",
    "    data_train = data_train.append(data_t)\n",
    "    n+=1\n",
    "\n",
    "print ('3. train and validation set created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4D2omEkGBomC"
   },
   "source": [
    "###(d)Check sizes after split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFHt0jjEBty2"
   },
   "outputs": [],
   "source": [
    "print (len(data_train))\n",
    "print (len(data_valid))\n",
    "print (len(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjPPACCpBvLJ"
   },
   "source": [
    "###(e)Downloading Images to existing folders in drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0T2LAnsXB8z8"
   },
   "source": [
    "Create directories 'N_train_images_model', 'M_validation_images_model', 'N_test_images_from_train' inside 'Data' folder before running the code below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jx_ja2cOOreq"
   },
   "outputs": [],
   "source": [
    "#function to fetch images\n",
    "def fetch_image(path,folder):\n",
    "    url=path\n",
    "    response=requests.get(url, stream=True)\n",
    "    path = '/content/drive/My Drive/APM_B10/'+ folder + '/image.jpg'\n",
    "    with open(path, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response.raw, out_file)\n",
    "    del response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PygrgZ5JOGbu",
    "outputId": "28f2065e-d52e-45b9-ae20-3983c9a35e62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. train images fetched\n"
     ]
    }
   ],
   "source": [
    "'''TRAIN SET - fetch images for the resized URLs and save in the already created directory train_images_model'''\n",
    "i=0\n",
    "for link in data_train['url']:              #looping over links to get images\n",
    "    if os.path.exists('../Data/N_train_images_model/'+str(data_train['id'].iloc[i])+'.jpg'):\n",
    "        i+=1\n",
    "        continue\n",
    "    fetch_image(link,'N_train_images_model')\n",
    "    os.rename('/content/drive/My Drive/APM_B10/N_train_images_model/image.jpg','/content/drive/My Drive/APM_B10/N_train_images_model/'+ str(data_train['id'].iloc[i])+ '.jpg')\n",
    "    i+=1\n",
    "#     if(i==50):   #uncomment to test in machine speed\n",
    "#         break \n",
    "print('4. train images fetched') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kT3Rm51CPslc",
    "outputId": "a0746632-d426-4659-c661-6329bb499be9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Validation images fetched\n"
     ]
    }
   ],
   "source": [
    "'''VALIDATION SET'''\n",
    "i=0\n",
    "for link in data_valid['url']:              #looping over links to get images\n",
    "    if os.path.exists('../Data/M_validation_images_model/'+str(data_valid['id'].iloc[i])+'.jpg'):\n",
    "        i+=1\n",
    "        continue\n",
    "    fetch_image(link,'M_validation_images_model')\n",
    "    os.rename('/content/drive/My Drive/APM_B10/M_validation_images_model/image.jpg','/content/drive/My Drive/APM_B10/M_validation_images_model/'+ str(data_valid['id'].iloc[i])+ '.jpg')\n",
    "    i+=1\n",
    "#     if(i==50):   #uncomment to test in your machine #took only 30 min?\n",
    "#         break\n",
    "print('5. Validation images fetched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_f-UBOOCs68",
    "outputId": "d0a9a4b2-ac33-4dbc-f6b4-e2da838fee16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Test images fetched\n"
     ]
    }
   ],
   "source": [
    "'''TEST SET'''\n",
    "i=0\n",
    "for link in data_test['url']:              #looping over links to get images\n",
    "    if os.path.exists('../Data/N_test_images_from_train/'+str(data_test['id'].iloc[i])+'.jpg'):\n",
    "        i+=1\n",
    "        continue\n",
    "    fetch_image(link,'N_test_images_from_train')\n",
    "    os.rename('/content/drive/My Drive/APM_B10/N_test_images_from_train/image.jpg','/content/drive/My Drive/APM_B10/N_test_images_from_train/'+ str(data_test['id'].iloc[i])+ '.jpg')\n",
    "    i+=1\n",
    "    # if(i==10):   #uncomment to test in your machine\n",
    "    #     break\n",
    "print('6. Test images fetched') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZEy3oqKDEkT"
   },
   "source": [
    "#4. Processing Downloaded Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsjevJf3GcNU"
   },
   "outputs": [],
   "source": [
    "#Data1 to be checked upon for next steps\n",
    "optimal_range = [str(x) for x in list(range(1000,2000))]\n",
    "data1 = df_filter[df_filter['landmark_id'].isin(optimal_range)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pP9IhYXhGd_E"
   },
   "source": [
    "###(a) Function to create folders for each class within train, valid, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lw23pfvGvNM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import urllib\n",
    "\n",
    "def createfolders(dataset,folder):\n",
    "    i = 0\n",
    "    while i < len(dataset):\n",
    "        landmark = str(dataset.landmark_id.iloc[i])\n",
    "        path = '/content/drive/My Drive/APM_B10/' + folder + '/'+ landmark\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJXVMf9KG4L4"
   },
   "source": [
    "###(b) Function to get rid of images with broken links (small sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxEq3-jFHBDK"
   },
   "outputs": [],
   "source": [
    "def transformdata(data,path1, path2):\n",
    "    n = 1\n",
    "    for landmark_id in set(data['landmark_id']):\n",
    "        t = data[(data.landmark_id == landmark_id)]\n",
    "        i = 1\n",
    "        r =[]\n",
    "        while i <= len(t.id):\n",
    "            it = i - 1\n",
    "            r.append(t.id.iloc[it])\n",
    "            i += 1\n",
    "        for files in os.listdir(rootdirpics):    # loop through startfolders\n",
    "            inpath = path1 + files\n",
    "            folder = str(landmark_id)\n",
    "            outpath = path2 + folder  \n",
    "            if ((files.split('.')[0] in r) & (os.path.getsize(inpath) >1000)):\n",
    "                print(outpath)\n",
    "                shutil.move(inpath, outpath)\n",
    "            elif ((files.split('.')[0] in r) & (os.path.getsize(inpath) <= 1000)):\n",
    "                os.remove(inpath) #delets small files that cannot be images\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz27GMsmEXF0"
   },
   "source": [
    "###(c) Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8O4EtitCE8pg"
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(data_train.landmark_id.value_counts())\n",
    "temp.reset_index(inplace=True)\n",
    "temp.columns = ['landmark_id','count']\n",
    "\n",
    "#make folders for landmark ID which had no images in validation sets\n",
    "available = [int((x[0].split('/'))[-1]) for x in os.walk(r'../Data/M_validation_images_model/') if len((x[0].split('/'))[-1]) > 0]\n",
    "new = [str(x) for x in range(1000,2999) if x not in available]\n",
    "for i in new:\n",
    "    path = '../Data/N_validation_images_model/' + i\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "createfolders(temp,'N_train_images_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjieEllFE8px"
   },
   "outputs": [],
   "source": [
    "rootdirpics = r'/content/drive/My Drive/APM_B10/N_train_images_model/'\n",
    "rootdirfolders = r'/content/drive/My Drive/APM_B10/N_train_images_model/'\n",
    "\n",
    "transformdata(data1,rootdirpics, rootdirfolders)\n",
    "print ('Train images moved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeVRmqqWEM65"
   },
   "source": [
    "###(d) Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzjyRTaZESR_"
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(data_valid.landmark_id.value_counts())\n",
    "temp.reset_index(inplace=True)\n",
    "temp.columns = ['landmark_id','count']\n",
    "\n",
    "createfolders(temp,'M_validation_images_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEujV9weEsAI"
   },
   "outputs": [],
   "source": [
    "rootdirpics = r'/content/drive/My Drive/APM_B10/M_validation_images_model/'\n",
    "rootdirfolders = r'/content/drive/My Drive/APM_B10/M_validation_images_model/'\n",
    "\n",
    "transformdata(data1,rootdirpics, rootdirfolders)\n",
    "print ('Vaidation images moved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nKHHJknESoj"
   },
   "source": [
    "###(e) Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhiDPR86FWDf"
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(data_test.landmark_id.value_counts())\n",
    "temp.reset_index(inplace=True)\n",
    "temp.columns = ['landmark_id','count']\n",
    "\n",
    "createfolders(temp,'N_test_images_from_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5irBUY0FWDw"
   },
   "outputs": [],
   "source": [
    "rootdirpics = r'/content/drive/My Drive/APM_B10/N_test_images_from_train/'\n",
    "rootdirfolders = r'/content/drive/My Drive/APM_B10/N_test_images_from_train/'\n",
    "\n",
    "transformdata(data1,rootdirpics, rootdirfolders)\n",
    "print ('Test images moved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfkgl7w7JZlD"
   },
   "source": [
    "###(f) Further cleaning to remove images in html that models cannot read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9rg2jqAMJ22T"
   },
   "outputs": [],
   "source": [
    "#TRAIN\n",
    "train_n_dir = r'/content/drive/My Drive/APM_B10/N_train_images_model/'\n",
    "train_n_landmark_list = []\n",
    "for i in os.listdir(validation_dir):\n",
    "  train_n_landmark_list.append(i)\n",
    "#train_n_landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTOtE_8dJ3Ed"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image #IMPORTANT, all images would be removed otherwise\n",
    "\n",
    "for landmark in train_n_landmark_list:\n",
    "  for i in os.listdir(train_n_dir + landmark):\n",
    "    try:\n",
    "      image.load_img(train_n_dir + landmark + '/' + i)\n",
    "    except:\n",
    "      train_n_html.append(train_n_dir + landmark + '/' + i)\n",
    "      print(train_n_dir + landmark + '/' + i)\n",
    "      os.remove(train_n_dir + landmark + '/' + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUi3EdDZLVXh"
   },
   "source": [
    "Run through each image in each sub-folder within the set.\n",
    "Remove the image if it cannot be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8wEnzyFJf8T"
   },
   "outputs": [],
   "source": [
    "#VALID\n",
    "validation_dir = r'/content/drive/My Drive/APM_B10/M_validation_images_model/'\n",
    "valid_n_landmark_list = []\n",
    "for i in os.listdir(validation_dir):\n",
    "  valid_n_landmark_list.append(i)\n",
    "#valid_n_landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoSLjN-fJtwP"
   },
   "outputs": [],
   "source": [
    "for landmark in valid_n_landmark_list:\n",
    "  for i in os.listdir(validation_dir + landmark):\n",
    "    try:\n",
    "      image.load_img(validation_dir + landmark + '/' + i)\n",
    "    except:\n",
    "      valid_n_html.append(validation_dir + landmark + '/' + i)\n",
    "      print(validation_dir + landmark + '/' + i)\n",
    "      os.remove(validation_dir + landmark + '/' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kRMgPC2J7ng"
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "test_n_dir = r'/content/drive/My Drive/APM_B10/N_test_images_from_train/'\n",
    "test_n_landmark_list = []\n",
    "for i in os.listdir(test_n_dir):\n",
    "  test_n_landmark_list.append(i)\n",
    "#test_n_landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxHiE6-3Ln43"
   },
   "outputs": [],
   "source": [
    "for landmark in test_n_landmark_list:\n",
    "  for i in os.listdir(test_n_dir + landmark):\n",
    "    try:\n",
    "      image.load_img(test_n_dir + landmark + '/' + i)\n",
    "    except:\n",
    "      test_n_landmark_list.append(test_n_dir + landmark + '/' + i)\n",
    "      print(test_n_dir + landmark + '/' + i)\n",
    "      os.remove(test_n_dir + landmark + '/' + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8orAJUmBM1F2"
   },
   "source": [
    "#5. Preperation for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EynfUi2M4fI"
   },
   "source": [
    "### (a) Step 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JN1yC21-4NZn",
    "ZEF1DFXb4OnQ",
    "VjC_mGnf46sO",
    "dAs-mTZD5Fuv",
    "n90O8ayH6YRx",
    "T41FuMt66_Is",
    "dzynRvYo7Ku7",
    "6ey0GKEa74gN",
    "pbHIebL49KbM",
    "aoKOH4_W-ABg",
    "wnVjvyUA-fy9",
    "Eg9xtMNAcbmu",
    "jIXwoFyEBNty",
    "4D2omEkGBomC",
    "GjPPACCpBvLJ",
    "3ZEy3oqKDEkT",
    "pP9IhYXhGd_E",
    "aJXVMf9KG4L4",
    "yz27GMsmEXF0",
    "HeVRmqqWEM65",
    "2nKHHJknESoj",
    "gfkgl7w7JZlD"
   ],
   "name": "Final_version.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
